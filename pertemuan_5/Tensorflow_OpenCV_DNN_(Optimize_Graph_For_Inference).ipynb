{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow - OpenCV DNN (Optimize Graph For Inference).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6baQ8wWMPkfO"
      },
      "source": [
        "# Faster R-CNN Training using Tensorflow\r\n",
        "___\r\n",
        "\r\n",
        "### Before started!\r\n",
        "- navigate to `Runtime` menu, and choose `change runtime type`,\r\n",
        "- then, change `hardware acceleration` to `GPU`\r\n",
        "- click `connect` button in top-right colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOpn4IebMl6p"
      },
      "source": [
        "# 1. Install Library\n",
        "### 1.A. Install Tensorflow 1.15 & OpenCV 4.4.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkvLlklwNhg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "858d94b7-60e8-456f-ca4a-6dabc48d3204"
      },
      "source": [
        "!pip install tensorflow_gpu==1.15"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.19.5)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.32.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_gpu==1.15) (53.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=c33eecdb87b0ebe2eb800e2ceb85ff8d020e153d0c989188c12b2410e56cad71\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, keras-applications, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmTVmjYeY4lU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c8ef9f-7830-4ed7-f82e-56217493b604"
      },
      "source": [
        "!pip install opencv-python==4.4.0.46\r\n",
        "!pip install opencv-contrib-python==4.4.0.46"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==4.4.0.46\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/80/10a9ae6fa0940f25af32739d1dc6dfdbbdc79af3f04c5ea1a6de4303cd54/opencv_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (49.5MB)\n",
            "\u001b[K     |████████████████████████████████| 49.5MB 67kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==4.4.0.46) (1.19.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-4.4.0.46\n",
            "Collecting opencv-contrib-python==4.4.0.46\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/ec/a66505cb25704066235369c8a1c1ed8d37b21f260f7b66d2cfa3264f0724/opencv_contrib_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (55.7MB)\n",
            "\u001b[K     |████████████████████████████████| 55.7MB 58kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==4.4.0.46) (1.19.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-4.4.0.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeyO_oSKdhsG"
      },
      "source": [
        "# 2. Download pretrained Tensorflow model\n",
        "\n",
        "- Pretrained model (Tensorflow 1 Model Zoo) : [[tensorflow github](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)]\n",
        "\n",
        "- Existing configs that has been tested in OpenCV DNN : <br>\n",
        "<table role=\"table\">\n",
        "<thead>\n",
        "<tr>\n",
        "<th>Model</th>\n",
        "<th>Version</th>\n",
        "<th></th>\n",
        "<th></th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr>\n",
        "<td>MobileNet-SSD v1</td>\n",
        "<td>2017_11_17</td>\n",
        "<td><a href=\"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/ssd_mobilenet_v1_coco_2017_11_17.pbtxt\">config</a></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>MobileNet-SSD v1 PPN</td>\n",
        "<td>2018_07_03</td>\n",
        "<td><a href=\"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03.tar.gz\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/ssd_mobilenet_v1_ppn_coco.pbtxt\">config</a></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>MobileNet-SSD v2</td>\n",
        "<td>2018_03_29</td>\n",
        "<td><a href=\"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/ssd_mobilenet_v2_coco_2018_03_29.pbtxt\">config</a></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Inception-SSD v2</td>\n",
        "<td>2017_11_17</td>\n",
        "<td><a href=\"http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/ssd_inception_v2_coco_2017_11_17.pbtxt\">config</a></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>MobileNet-SSD v3 (see <a href=\"https://github.com/opencv/opencv/pull/16760\">#16760</a>)</td>\n",
        "<td>2020_01_14</td>\n",
        "<td><a href=\"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://gist.github.com/dkurt/54a8e8b51beb3bd3f770b79e56927bd7\">config</a></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Faster-RCNN Inception v2</td>\n",
        "<td>2018_01_28</td>\n",
        "<td><a href=\"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/faster_rcnn_inception_v2_coco_2018_01_28.pbtxt\">config</a></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Faster-RCNN ResNet-50</td>\n",
        "<td>2018_01_28</td>\n",
        "<td><a href=\"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/faster_rcnn_resnet50_coco_2018_01_28.pbtxt\">config</a></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Mask-RCNN Inception v2</td>\n",
        "<td>2018_01_28</td>\n",
        "<td><a href=\"http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\">config</a></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>EfficientDet-D0 (see <a href=\"https://github.com/opencv/opencv/pull/17384\">#17384</a>)</td>\n",
        "<td></td>\n",
        "<td><a href=\"https://www.dropbox.com/s/9mqp99fd2tpuqn6/efficientdet-d0.pb?dl=1\" rel=\"nofollow\">weights</a></td>\n",
        "<td><a href=\"https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/efficientdet-d0.pbtxt\">config</a></td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUDk1gLQsWOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b5888d-a840-46ff-bef0-25b847d2245f"
      },
      "source": [
        "%rm -rf /content/tf_models\n",
        "%mkdir /content/tf_models\n",
        "%cd /content/tf_models\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "\n",
        "MODELS = ['ssd_mobilenet_v2_coco_2018_03_29',\n",
        "          'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "          'faster_rcnn_resnet50_coco_2018_01_28',\n",
        "          'mask_rcnn_inception_v2_coco_2018_01_28']\n",
        "\n",
        "#DEST_DIR = '/content/tf_models/'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "for MODEL in MODELS:\n",
        "  MODEL_FILE = MODEL + '.tar.gz'\n",
        "\n",
        "  with urllib.request.urlopen(DOWNLOAD_BASE+MODEL_FILE) as response, open(MODEL_FILE, 'wb') as out_file:\n",
        "    shutil.copyfileobj(response, out_file)\n",
        "\n",
        "  tar = tarfile.open(MODEL_FILE)\n",
        "  tar.extractall()\n",
        "  tar.close()\n",
        "\n",
        "  os.remove(MODEL_FILE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tf_models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0lD68qeK3ot"
      },
      "source": [
        "# 3. Clone OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihXqao1jK6iD",
        "outputId": "17ae6ffc-5718-44a7-e131-6678f4f97352"
      },
      "source": [
        "%cd /content/\r\n",
        "!git clone https://github.com/opencv/opencv.git\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'opencv'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 287935 (delta 0), reused 0 (delta 0), pack-reused 287934\u001b[K\n",
            "Receiving objects: 100% (287935/287935), 477.07 MiB | 32.50 MiB/s, done.\n",
            "Resolving deltas: 100% (201167/201167), done.\n",
            "Checking out files: 100% (6746/6746), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M670D9fFLnR8",
        "outputId": "e2c8d874-0251-4d7d-cc8b-841f3ded039c"
      },
      "source": [
        "!ls opencv/samples/dnn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "action_recognition.py  fast_neural_style.py\t  scene_text_detection.cpp\n",
            "classification.cpp     human_parsing.cpp\t  scene_text_recognition.cpp\n",
            "classification.py      human_parsing.py\t\t  scene_text_spotting.cpp\n",
            "CMakeLists.txt\t       js_face_recognition.html   segmentation.cpp\n",
            "colorization.cpp       mask_rcnn.py\t\t  segmentation.py\n",
            "colorization.py        mobilenet_ssd_accuracy.py  shrink_tf_graph_weights.py\n",
            "common.hpp\t       models.yml\t\t  siamrpnpp.py\n",
            "common.py\t       object_detection.cpp\t  text_detection.cpp\n",
            "custom_layers.hpp      object_detection.py\t  text_detection.py\n",
            "dasiamrpn_tracker.cpp  openpose.cpp\t\t  tf_text_graph_common.py\n",
            "dasiamrpn_tracker.py   openpose.py\t\t  tf_text_graph_efficientdet.py\n",
            "dnn_model_runner       optical_flow.py\t\t  tf_text_graph_faster_rcnn.py\n",
            "download_models.py     person_reid.cpp\t\t  tf_text_graph_mask_rcnn.py\n",
            "edge_detection.py      person_reid.py\t\t  tf_text_graph_ssd.py\n",
            "face_detector\t       README.md\t\t  virtual_try_on.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YAGmBifasRy"
      },
      "source": [
        "# 4. Generate OpenCV DNN Config for Inference\r\n",
        "- Generate Config file (use one of the scripts which generate a text graph representation for a frozen .pb model depends on its architecture):\r\n",
        "  - tf_text_graph_ssd.py\r\n",
        "  - tf_text_graph_faster_rcnn.py\r\n",
        "  - tf_text_graph_mask_rcnn.py\r\n",
        "  - tf_text_graph_efficientdet.py\r\n",
        "- generate `faster_rcnn_inception_v2_coco_2018_01_28.pbtxt` for OpenCV DNN inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKsDngRZas5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839ff541-0653-43dc-dfb9-b6206e208521"
      },
      "source": [
        "%mkdir -p /content/graph_text\r\n",
        "%cd /content/\r\n",
        "\r\n",
        "!python opencv/samples/dnn/tf_text_graph_faster_rcnn.py \\\r\n",
        "    --input tf_models/faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb \\\r\n",
        "    --output graph_text/faster_rcnn_inception_v2_coco_2018_01_28.pbtxt \\\r\n",
        "    --config tf_models/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Number of classes: 90\n",
            "Scales:            [0.25, 0.5, 1.0, 2.0]\n",
            "Aspect ratios:     [0.5, 1.0, 2.0]\n",
            "Width stride:      16.000000\n",
            "Height stride:     16.000000\n",
            "Features stride:   16.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BRgSqbvMf67"
      },
      "source": [
        "- generate `faster_rcnn_resnet50_coco_2018_01_28.pbtxt` for OpenCV DNN inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0JdbblKMnAv",
        "outputId": "261ce9c1-d000-4099-ac8c-bdf80f777da7"
      },
      "source": [
        "%mkdir -p /content/graph_text\r\n",
        "%cd /content/\r\n",
        "\r\n",
        "!python opencv/samples/dnn/tf_text_graph_faster_rcnn.py \\\r\n",
        "    --input tf_models/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb \\\r\n",
        "    --output graph_text/faster_rcnn_resnet50_coco_2018_01_28.pbtxt \\\r\n",
        "    --config tf_models/faster_rcnn_resnet50_coco_2018_01_28/pipeline.config"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Number of classes: 90\n",
            "Scales:            [0.25, 0.5, 1.0, 2.0]\n",
            "Aspect ratios:     [0.5, 1.0, 2.0]\n",
            "Width stride:      16.000000\n",
            "Height stride:     16.000000\n",
            "Features stride:   16.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx-oe-orMv7p"
      },
      "source": [
        "- generate `mask_rcnn_inception_v2_coco_2018_01_28.pbtxt` for OpenCV DNN inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioQ3pTQnM3FO",
        "outputId": "43a565aa-647e-4f7d-8977-7a09353987fc"
      },
      "source": [
        "%mkdir -p /content/graph_text\r\n",
        "%cd /content/\r\n",
        "\r\n",
        "!python opencv/samples/dnn/tf_text_graph_mask_rcnn.py \\\r\n",
        "    --input tf_models/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb \\\r\n",
        "    --output graph_text/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt \\\r\n",
        "    --config tf_models/mask_rcnn_inception_v2_coco_2018_01_28/pipeline.config"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Number of classes: 90\n",
            "Scales:            [0.25, 0.5, 1.0, 2.0]\n",
            "Aspect ratios:     [0.5, 1.0, 2.0]\n",
            "Width stride:      16.000000\n",
            "Height stride:     16.000000\n",
            "Features stride:   16.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MauUdSv8NawM"
      },
      "source": [
        "- generate `ssd_mobilenet_v2_coco_2018_03_29.pbtxt` for OpenCV DNN inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyHZUOcbNbxO",
        "outputId": "a8bd1abb-9554-433a-ab49-1a4512c1fdb4"
      },
      "source": [
        "%mkdir -p /content/graph_text\r\n",
        "%cd /content/\r\n",
        "\r\n",
        "!python opencv/samples/dnn/tf_text_graph_ssd.py \\\r\n",
        "    --input tf_models/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb \\\r\n",
        "    --output graph_text/ssd_mobilenet_v2_coco_2018_03_29.pbtxt \\\r\n",
        "    --config tf_models/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Scale: [0.200000-0.950000]\n",
            "Aspect ratios: [1.0, 2.0, 0.5, 3.0, 0.333299994469]\n",
            "Reduce boxes in the lowest layer: True\n",
            "Number of classes: 90\n",
            "Number of layers: 6\n",
            "box predictor: convolutional\n",
            "Input image size: 300x300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dhHNprHQwQP"
      },
      "source": [
        "# 10. Zip  & Download Inference Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lnuQmDhRGbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "7db2bbba-8189-481a-86fe-68e7469d6b1e"
      },
      "source": [
        "%cd /content/\r\n",
        "!zip -r inference_graph.zip graph_text/ \\\r\n",
        "    tf_models/faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb \\\r\n",
        "    tf_models/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb \\\r\n",
        "    tf_models/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb \\\r\n",
        "    tf_models/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\r\n",
        "    \r\n",
        "from google.colab import files\r\n",
        "files.download(\"inference_graph.zip\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "  adding: graph_text/ (stored 0%)\n",
            "  adding: graph_text/ssd_mobilenet_v2_coco_2018_03_29.pbtxt (deflated 96%)\n",
            "  adding: graph_text/faster_rcnn_inception_v2_coco_2018_01_28.pbtxt (deflated 95%)\n",
            "  adding: graph_text/faster_rcnn_resnet50_coco_2018_01_28.pbtxt (deflated 95%)\n",
            "  adding: graph_text/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt (deflated 96%)\n",
            "  adding: tf_models/faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb (deflated 13%)\n",
            "  adding: tf_models/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb (deflated 10%)\n",
            "  adding: tf_models/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb (deflated 12%)\n",
            "  adding: tf_models/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb (deflated 10%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8551240a-f5fb-4029-b4f5-6e5c67cbeab5\", \"inference_graph.zip\", 279936674)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfa2ew_pRdZa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}